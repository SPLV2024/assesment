# -*- coding: utf-8 -*-
"""LVADSUSR_SASwata_Pradhan_Annomaly.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sjGO2CSirTGjJFq7RvkPZmbB4UdI1oa3
"""

url= 'https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/anomaly_train.csv'

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd
data = pd.read_csv(url)
df=pd.DataFrame(data)
df.columns

df.isnull().sum()

df.head()

df.drop('TransactionID',axis=1,inplace=True)

outlier_model = IsolationForest(contamination=0.1, random_state=42)
outliers = outlier_model.fit_predict(data[['Amount', 'Time', 'User']])
data['is_outlier'] = outliers

data.describe()
print(data.shape)
print(data.info())
# Summary statistics
print(data.describe())

data.hist(figsize=(10, 8))
plt.tight_layout()
plt.show()

sns.pairplot(data, diag_kind='kde')
plt.show()

label_encoder = LabelEncoder()
data['Type'] = label_encoder.fit_transform(data['Type'])
data['Location'] = label_encoder.fit_transform(data['Location'])


features = ['Amount', 'Time', 'User']

X = data[features]
y = data['is_outlier']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = IsolationForest(n_estimators=100, contamination=0.1, max_features=3, max_samples=10000, random_state=42)
model.fit(X_train)
y_pred = model.predict(X_train)

data["anomaly_score"] = model.decision_function(X)

anomalies = data.loc[data["anomaly_score"] < 0]

plt.scatter(data["Amount"], data["anomaly_score"], label="Not Anomaly")
plt.scatter(anomalies["Amount"], anomalies["anomaly_score"], color="r", label="Anomaly")
plt.xlabel("Social Connections")
plt.ylabel("Anomaly Score")
plt.legend()
plt.show()

